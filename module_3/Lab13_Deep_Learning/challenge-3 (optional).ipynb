{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge: Spiral Data Classification\n",
    "\n",
    "Now that you completed Challenge 2, you know you can use the Tensorflow Playground to experiment the hyperparameters of your deep learning model. If you are brave enough to take on this challenge, we present you the spiral data generated by codes and you will replicate your model built visually in the Tensorflow Playground with Python codes.\n",
    "\n",
    "Below are the codes to generate the spiral dataset. Read the remarks and execute the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import hypot, cos, sin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "A function to generate X/Y data points that will form a spiral.\n",
    "\"\"\"\n",
    "def spiral(radius, step, resolution=.1, angle=0.0, start=0.0):\n",
    "    dist = start\n",
    "    coords=[]\n",
    "    while dist*hypot(cos(angle),sin(angle))<radius:\n",
    "        cord=[]\n",
    "        cord.append(dist*cos(angle))\n",
    "        cord.append(dist*sin(angle))\n",
    "        coords.append(cord)\n",
    "        dist+=step\n",
    "        angle+=resolution\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two sets of spiral data points with opposite angles\n",
    "data_1 = np.array(spiral(1000, 5, angle=0))\n",
    "data_2 = np.array(spiral(1000, 5, angle=180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the two datasets to visualize the spirals\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "a, b = data_1.T\n",
    "plt.scatter(a, b, s=5)\n",
    "\n",
    "aa, bb = data_2.T\n",
    "plt.scatter(aa, bb, s=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    201\n",
       "1    200\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two spiral datasets into one\n",
    "\n",
    "df1 = pd.DataFrame(data=data_1, columns=[\"X\", \"Y\"])\n",
    "df1[\"CLASS\"] = 0\n",
    "\n",
    "df2 = pd.DataFrame(data=data_2, columns=[\"X\", \"Y\"])\n",
    "df2[\"CLASS\"] = 1\n",
    "\n",
    "df = df1.append(df2)\n",
    "df['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build a neural network with Tensorflow to classify `df`. See how low data loss and how high accuracy can you achieve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['xy']=df.X*df.Y\n",
    "df['x2']=df.X**2\n",
    "df['y2']=df.Y**2\n",
    "df['sinx']=np.sin(df.X)\n",
    "df['siny']=np.sin(df.Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>xy</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>sinx</th>\n",
       "      <th>siny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.975021</td>\n",
       "      <td>0.499167</td>\n",
       "      <td>0</td>\n",
       "      <td>2.483367</td>\n",
       "      <td>24.750832</td>\n",
       "      <td>0.249168</td>\n",
       "      <td>-0.965710</td>\n",
       "      <td>0.478694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.800666</td>\n",
       "      <td>1.986693</td>\n",
       "      <td>0</td>\n",
       "      <td>19.470917</td>\n",
       "      <td>96.053050</td>\n",
       "      <td>3.946950</td>\n",
       "      <td>-0.367099</td>\n",
       "      <td>0.914754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.330047</td>\n",
       "      <td>4.432803</td>\n",
       "      <td>0</td>\n",
       "      <td>63.522278</td>\n",
       "      <td>205.350257</td>\n",
       "      <td>19.649743</td>\n",
       "      <td>0.981456</td>\n",
       "      <td>-0.961170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.421220</td>\n",
       "      <td>7.788367</td>\n",
       "      <td>0</td>\n",
       "      <td>143.471218</td>\n",
       "      <td>339.341342</td>\n",
       "      <td>60.658658</td>\n",
       "      <td>-0.415358</td>\n",
       "      <td>0.997848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X         Y  CLASS          xy          x2         y2      sinx  \\\n",
       "0   0.000000  0.000000      0    0.000000    0.000000   0.000000  0.000000   \n",
       "1   4.975021  0.499167      0    2.483367   24.750832   0.249168 -0.965710   \n",
       "2   9.800666  1.986693      0   19.470917   96.053050   3.946950 -0.367099   \n",
       "3  14.330047  4.432803      0   63.522278  205.350257  19.649743  0.981456   \n",
       "4  18.421220  7.788367      0  143.471218  339.341342  60.658658 -0.415358   \n",
       "\n",
       "       siny  \n",
       "0  0.000000  \n",
       "1  0.478694  \n",
       "2  0.914754  \n",
       "3 -0.961170  \n",
       "4  0.997848  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(columns='CLASS')\n",
    "y=df.CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X_scaled = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 7)\n",
      "(81, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=42)\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras specific\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_rate=0.001\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, input_dim=7, activation='relu'))\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(200,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile a model\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam',),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 1s 6ms/step - loss: 0.6989 - accuracy: 0.5094\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.4344\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5281\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5250\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5188\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5312\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5344\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5344\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5469\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6927 - accuracy: 0.5344\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.5437\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5281\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.5375\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.5375\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5375\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.5312\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.5219\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5250\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.5344\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.5469\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.5250\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.5437\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5437\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.5406\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5406\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6862 - accuracy: 0.5344\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.5312\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.5437\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.5500\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5562\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.5469\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.5500\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5156\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.5000\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.5188\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.5250\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.5344\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.5312\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.5094\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.5562\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6764 - accuracy: 0.5375\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6746 - accuracy: 0.5406\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.5406\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.5344\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6763 - accuracy: 0.5281\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6741 - accuracy: 0.5531\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6780 - accuracy: 0.5312\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.5312\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.5437\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6729 - accuracy: 0.5469\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.5094\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5437\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6782 - accuracy: 0.5031\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.5469\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.5281\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.5063\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.5312\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.5437\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.5156\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.5188\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.5469\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.5125\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.5219\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.5375\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.5531: 0s - loss: 0.6930 - accuracy: 0.\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6727 - accuracy: 0.4906\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.4906\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.5125\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.5469\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6768 - accuracy: 0.5469\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.5469\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.5437\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6704 - accuracy: 0.5469\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6695 - accuracy: 0.5469: 0s - loss: 0.6626 - accuracy: 0.57\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.5219\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.5406\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.5344\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.5250\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.5562\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.5312\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6575 - accuracy: 0.5188\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6558 - accuracy: 0.5219\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6518 - accuracy: 0.5375\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.5312\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.5219\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.5281\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6774 - accuracy: 0.5375\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.5469\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.5094\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.5437\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6639 - accuracy: 0.5437\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.5156\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6678 - accuracy: 0.5344\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.5437\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.5500\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6660 - accuracy: 0.5406\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6654 - accuracy: 0.5344\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.5469\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.5469\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6448 - accuracy: 0.54 - 0s 6ms/step - loss: 0.6472 - accuracy: 0.5469\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.5469\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6509 - accuracy: 0.5469\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.5531\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.5063\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6501 - accuracy: 0.5250\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6505 - accuracy: 0.5437\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6505 - accuracy: 0.5219\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.5125\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6725 - accuracy: 0.5469\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6633 - accuracy: 0.5531\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6663 - accuracy: 0.5250\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6729 - accuracy: 0.5125\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6637 - accuracy: 0.5312\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6546 - accuracy: 0.5375\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6669 - accuracy: 0.5250\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.5562\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6557 - accuracy: 0.5344\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.5344\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6678 - accuracy: 0.5469\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6664 - accuracy: 0.5437\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.5406\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6634 - accuracy: 0.5344\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6570 - accuracy: 0.5250\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6528 - accuracy: 0.5531\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6526 - accuracy: 0.5531\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6437 - accuracy: 0.5625\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.5500\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.5531\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6498 - accuracy: 0.5375\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.5594\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6610 - accuracy: 0.5531\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6495 - accuracy: 0.5625\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6541 - accuracy: 0.5156\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6493 - accuracy: 0.5437\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.5437\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6437 - accuracy: 0.5469: 0s - loss: 0.6444 - accuracy: 0.55 - ETA: 0s - loss: 0.6442 - accuracy: 0.55\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6437 - accuracy: 0.5625\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6381 - accuracy: 0.5531\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6404 - accuracy: 0.5656\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6380 - accuracy: 0.5719\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6459 - accuracy: 0.5531\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6493 - accuracy: 0.5469\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.5375\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6572 - accuracy: 0.5437\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6526 - accuracy: 0.5469\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.5406\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6488 - accuracy: 0.5594\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6452 - accuracy: 0.5469\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6401 - accuracy: 0.5750: 0s - loss: 0.6484 - accuracy\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6357 - accuracy: 0.5719\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6374 - accuracy: 0.5656\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6297 - accuracy: 0.5688\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6276 - accuracy: 0.5813\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6381 - accuracy: 0.5656\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6302 - accuracy: 0.5531\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6261 - accuracy: 0.5875\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6279 - accuracy: 0.5719: 0s - loss: 0.6239 - accuracy: \n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6542 - accuracy: 0.5094\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6590 - accuracy: 0.5406\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6528 - accuracy: 0.5281\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6506 - accuracy: 0.5406\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6627 - accuracy: 0.55 - 0s 6ms/step - loss: 0.6645 - accuracy: 0.5500\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6548 - accuracy: 0.5344\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6486 - accuracy: 0.5469\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6520 - accuracy: 0.5406\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6412 - accuracy: 0.5500\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6370 - accuracy: 0.5656\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6337 - accuracy: 0.5594\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6406 - accuracy: 0.5406\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.5344: 0s - loss: 0.6344 - accuracy: 0.53\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6376 - accuracy: 0.5781\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6266 - accuracy: 0.5781\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.5531\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6356 - accuracy: 0.5656\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6228 - accuracy: 0.5719\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6228 - accuracy: 0.5625\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6319 - accuracy: 0.5906\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.5781\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6204 - accuracy: 0.5750\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.5813\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.5406\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.5500\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6396 - accuracy: 0.5562\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.5531\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.5531\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.5625\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.5562\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.5719\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.5688\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.5719\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.5688\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.5469\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.5500\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.5562\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.5656\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.5562\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.5719\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6381 - accuracy: 0.5719\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.5625\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.5344\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.5375\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.5375\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.5500\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.5625\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.5562\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.5531\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.5656\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.5500\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.5750\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.5469\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.5531\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6316 - accuracy: 0.5719\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.5688\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6340 - accuracy: 0.5813\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.5813\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.5969\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.5875\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6227 - accuracy: 0.5844\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6182 - accuracy: 0.5875\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6277 - accuracy: 0.5781\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.5844\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.5875\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.5875\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.5813\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.5844\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.5969\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6098 - accuracy: 0.5875\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6107 - accuracy: 0.5969\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.5625\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.5750\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6222 - accuracy: 0.5781\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.5844\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.5469\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.5344\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.5719\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.5750\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.5625\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.5875\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.5844\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.5656\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6117 - accuracy: 0.5938\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.5969\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.5750\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.5813\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6450 - accuracy: 0.5844\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.5781\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.5781\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.5688\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.5656\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.5594\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.5594\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6345 - accuracy: 0.5688\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.5656\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6334 - accuracy: 0.5906\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6343 - accuracy: 0.5688\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.5656\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6511 - accuracy: 0.5594\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.5875\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.5656\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.5531\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6430 - accuracy: 0.5594\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.5781\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.5813\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.5656\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.5625\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6593 - accuracy: 0.5344\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.5562\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.5469\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.5719\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.5719\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.5625\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6389 - accuracy: 0.5719\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.5500\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.5562\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6368 - accuracy: 0.5969\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6419 - accuracy: 0.5437\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.5969\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.5813\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.5562\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.5594\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.5781\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.5781\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.5781\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6383 - accuracy: 0.5938\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.5875\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.5781\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.5813\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6308 - accuracy: 0.5844\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6310 - accuracy: 0.6000\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6335 - accuracy: 0.5969\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.5781\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.5406\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.5813\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6332 - accuracy: 0.5437\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.5844\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6211 - accuracy: 0.5969\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6141 - accuracy: 0.5938\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.5719\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6145 - accuracy: 0.59 - 0s 6ms/step - loss: 0.6134 - accuracy: 0.5969\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6131 - accuracy: 0.5781\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6153 - accuracy: 0.5875\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6120 - accuracy: 0.6000\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6033 - accuracy: 0.6031\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6128 - accuracy: 0.5813\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.6187\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.6219\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6259 - accuracy: 0.5813\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6132 - accuracy: 0.5875\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.6094\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5994 - accuracy: 0.6219\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.5906\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6280 - accuracy: 0.5938\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6186 - accuracy: 0.5938\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6096 - accuracy: 0.5906\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6200 - accuracy: 0.5813\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6359 - accuracy: 0.5719\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6208 - accuracy: 0.5719\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5986 - accuracy: 0.6094\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5942 - accuracy: 0.6156\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6002 - accuracy: 0.6031\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.6250\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6003 - accuracy: 0.5906\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5962 - accuracy: 0.6250\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5947 - accuracy: 0.6094\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5928 - accuracy: 0.6062: 0s - loss: 0.5937 - accuracy\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6117 - accuracy: 0.5813\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6034 - accuracy: 0.5938\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.5980 - accuracy: 0.5906\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.5940 - accuracy: 0.6000\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6308 - accuracy: 0.5875: 0s - loss: 0.6343 - accuracy: 0.\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6168 - accuracy: 0.5906\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6049 - accuracy: 0.6031\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6264 - accuracy: 0.5813\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6125 - accuracy: 0.5750\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5961 - accuracy: 0.5906\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5937 - accuracy: 0.6062\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5910 - accuracy: 0.6000\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.5949 - accuracy: 0.6219\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.5872 - accuracy: 0.6125\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5867 - accuracy: 0.5938\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5837 - accuracy: 0.6250\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5842 - accuracy: 0.5844\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.5821 - accuracy: 0.5938\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5765 - accuracy: 0.6187: 0s - loss: 0.5765 - accuracy: 0.63\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5752 - accuracy: 0.6438\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6112 - accuracy: 0.5813\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6588 - accuracy: 0.5906\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6387 - accuracy: 0.5375\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6329 - accuracy: 0.5938\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6696 - accuracy: 0.5562\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6524 - accuracy: 0.5188\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6494 - accuracy: 0.5250\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6379 - accuracy: 0.5469 0s - loss: 0.6334 - accuracy: \n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.7510 - accuracy: 0.5750\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6682 - accuracy: 0.5063 0s - loss: 0.6474 - accura\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6641 - accuracy: 0.5625\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6628 - accuracy: 0.5375\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6515 - accuracy: 0.5469: 0s - loss: 0.6501 - accuracy: 0.55\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6379 - accuracy: 0.5719\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6264 - accuracy: 0.5688\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6212 - accuracy: 0.5719\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6284 - accuracy: 0.5531\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6172 - accuracy: 0.5781\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6140 - accuracy: 0.5750\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6182 - accuracy: 0.5813\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6138 - accuracy: 0.5562\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6046 - accuracy: 0.5906\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6063 - accuracy: 0.5813\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6167 - accuracy: 0.5688\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.5688: 0s - loss: 0.6205 - accuracy: 0.56\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6105 - accuracy: 0.5750\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6163 - accuracy: 0.5719 0s - loss: 0.6528 - accura\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6408 - accuracy: 0.5625\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6239 - accuracy: 0.5688\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6137 - accuracy: 0.5781\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6046 - accuracy: 0.6250\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6157 - accuracy: 0.6000\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6087 - accuracy: 0.5875\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5933 - accuracy: 0.6125\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6134 - accuracy: 0.5906\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6025 - accuracy: 0.6000\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5928 - accuracy: 0.6219\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5840 - accuracy: 0.6000\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6278 - accuracy: 0.5781\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6050 - accuracy: 0.5875\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5917 - accuracy: 0.6187\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.5969\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6041 - accuracy: 0.6000\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5999 - accuracy: 0.6156\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5928 - accuracy: 0.5875\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5807 - accuracy: 0.6125\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6732 - accuracy: 0.5719\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6415 - accuracy: 0.5625: 0s - loss: 0.6336 - accuracy\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6352 - accuracy: 0.5531\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6304 - accuracy: 0.5594\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6275 - accuracy: 0.5531: 0s - loss: 0.6297 - accuracy: \n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6252 - accuracy: 0.5688\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6266 - accuracy: 0.5688\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6242 - accuracy: 0.5469\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6217 - accuracy: 0.5656\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6217 - accuracy: 0.5656\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6226 - accuracy: 0.5750\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6206 - accuracy: 0.5781\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6263 - accuracy: 0.5750\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6166 - accuracy: 0.5875\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6255 - accuracy: 0.5750\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6255 - accuracy: 0.6000: 0s - loss: 0.6250 - accuracy: 0.\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.5625\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6245 - accuracy: 0.5813\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6234 - accuracy: 0.5656\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6228 - accuracy: 0.5719\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6258 - accuracy: 0.6094\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6204 - accuracy: 0.5969: 0s - loss: 0.6282 - accuracy: \n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6474 - accuracy: 0.6219\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6334 - accuracy: 0.5969\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6268 - accuracy: 0.5969\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6230 - accuracy: 0.5938\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6219 - accuracy: 0.5938\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6222 - accuracy: 0.6000\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6193 - accuracy: 0.5969\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6165 - accuracy: 0.6375\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6179 - accuracy: 0.6094\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6127 - accuracy: 0.6187\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.6125\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6088 - accuracy: 0.6187\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5979 - accuracy: 0.6187: 0s - loss: 0.5982 - accuracy: 0.\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5943 - accuracy: 0.6156\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5986 - accuracy: 0.6156\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5872 - accuracy: 0.6281\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.6281\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5825 - accuracy: 0.6187\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.6156\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.6094\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5963 - accuracy: 0.6156\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5846 - accuracy: 0.6344\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6136 - accuracy: 0.5938\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5985 - accuracy: 0.5906\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6012 - accuracy: 0.6094\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.5813\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5885 - accuracy: 0.6281\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5849 - accuracy: 0.5969\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5819 - accuracy: 0.6187\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5859 - accuracy: 0.6187\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5946 - accuracy: 0.5938\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5871 - accuracy: 0.6313\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5800 - accuracy: 0.5938\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5664 - accuracy: 0.6406\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5639 - accuracy: 0.6531\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5745 - accuracy: 0.6094\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5935 - accuracy: 0.6344\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5854 - accuracy: 0.6000\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5859 - accuracy: 0.6375\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6239 - accuracy: 0.6125\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6730 - accuracy: 0.5813: 0s - loss: 0.6839 - accuracy: 0.57\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6120 - accuracy: 0.5938\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6026 - accuracy: 0.6094\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6027 - accuracy: 0.6000\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5998 - accuracy: 0.6125\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6026 - accuracy: 0.5719\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5972 - accuracy: 0.5969\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5990 - accuracy: 0.6250\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5984 - accuracy: 0.6219\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.6094\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5861 - accuracy: 0.6156\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5899 - accuracy: 0.6156\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5987 - accuracy: 0.6062\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5804 - accuracy: 0.6344\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5843 - accuracy: 0.6250: 0s - loss: 0.5857 - accuracy: 0.62\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5999 - accuracy: 0.5938\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5861 - accuracy: 0.6094\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5779 - accuracy: 0.6187\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5778 - accuracy: 0.6219\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5684 - accuracy: 0.6219\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5661 - accuracy: 0.6313\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5687 - accuracy: 0.6125\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5794 - accuracy: 0.6094\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5632 - accuracy: 0.6031\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5618 - accuracy: 0.6406\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5634 - accuracy: 0.6281\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5733 - accuracy: 0.6344\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6341 - accuracy: 0.5938\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6019 - accuracy: 0.6156\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5863 - accuracy: 0.6344: 0s - loss: 0.6133 - accuracy\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5689 - accuracy: 0.6438\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5965 - accuracy: 0.5875\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5944 - accuracy: 0.5813\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5619 - accuracy: 0.6187\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5656 - accuracy: 0.6219\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5531 - accuracy: 0.6344\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5618 - accuracy: 0.6250\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5541 - accuracy: 0.6031\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6179 - accuracy: 0.6344\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.7030 - accuracy: 0.5437\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6231 - accuracy: 0.5844\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6190 - accuracy: 0.5813\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6135 - accuracy: 0.5969\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6081 - accuracy: 0.5844\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6398 - accuracy: 0.5531\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6280 - accuracy: 0.5813\n",
      "Accuracy on training data: 0.596875011920929% \n",
      " Error on training data: 0.40312498807907104\n",
      "Accuracy on test data: 0.5308641791343689% \n",
      " Error on test data: 0.4691358208656311,\n",
      " Loss: 0.7206465005874634\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=10)\n",
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(X_test)\n",
    "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {},\\n Loss: {}'.format(scores2[1], 1 - scores2[1], scores2[0]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x186677bb3d0>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the explenation of that problem that I found on this website. The code below I copied from there, but it still doesn't improve the accuracy. Therefore I will accept the results from my model above with 64% of accuracy on train and 53% on test sets.\n",
    "\n",
    "# https://glowingpython.blogspot.com/2017/04/solving-two-spirals-problem-with-keras.html\n",
    "mymlp = Sequential()\n",
    "mymlp.add(Dense(12, input_dim=7, activation='tanh'))\n",
    "mymlp.add(Dense(12, activation='tanh'))\n",
    "mymlp.add(Dense(12, activation='tanh'))\n",
    "mymlp.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "mymlp.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "mymlp.fit(X_train, y_train, epochs=150, batch_size=10,  verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5500\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5250\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.5312\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.5188\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.4750\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.5344\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6694 - accuracy: 0.5156\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.5469\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.5469\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.5406\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.5219\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.5656\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6667 - accuracy: 0.5188\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.5406\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.5031\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.5500\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.5437\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.4875\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.5031: 0s - loss: 0.6594 - accuracy: 0.\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.5562\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.5219\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.5437\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.5063\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.5063\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.5344\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6667 - accuracy: 0.5344\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5219\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.5344\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.5375\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.5844\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.5094\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.5156\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.5344\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.5375\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.5125\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.5188\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.5094\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.5250\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.5031\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5344\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6663 - accuracy: 0.5125\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.5125\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5469\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5469\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.4938\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.5312\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.5437\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.5375\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.5125\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.5531\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.5594\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.5375\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.5281\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.5469\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.5281\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.5500\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.5469\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.5406\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.5188\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.5531\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.5312\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.5063\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5281\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.4812\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.5031\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.5188\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.5031\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.5125\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5156\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.5219\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.5312\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5281\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.5156\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6655 - accuracy: 0.5469\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.5094\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.5531\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6669 - accuracy: 0.4969\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.5562\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.5312\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6675 - accuracy: 0.5156\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.5406\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.5063\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6522 - accuracy: 0.53 - 0s 3ms/step - loss: 0.6638 - accuracy: 0.5156\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6693 - accuracy: 0.4750\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.5094\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6659 - accuracy: 0.5094\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6656 - accuracy: 0.5031\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6609 - accuracy: 0.5469\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.5125\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.4969\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.5250\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.4875\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.5219\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.5281\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6644 - accuracy: 0.5125\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6645 - accuracy: 0.5500\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6671 - accuracy: 0.5250\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6636 - accuracy: 0.5375\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6674 - accuracy: 0.5156\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6578 - accuracy: 0.5844\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.5281\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.5406\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6636 - accuracy: 0.5437\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.5500\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.5312\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6652 - accuracy: 0.5188\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6622 - accuracy: 0.5250\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.5531\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6652 - accuracy: 0.4969\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.5156\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.5219\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.5281\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6674 - accuracy: 0.5437\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.5031\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5000\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.5000\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6661 - accuracy: 0.5063\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.5250\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6660 - accuracy: 0.5281\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.4844\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5094\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.5063\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6666 - accuracy: 0.5094\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5281\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.5312\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.5063: 0s - loss: 0.6635 - accuracy: 0.51\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5094\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.5406\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.5531\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.4906\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.5344\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.5063\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.5344\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6646 - accuracy: 0.5156\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6652 - accuracy: 0.5000\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.5156\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.5437\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.5500\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.5625\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.5188: 0s - loss: 0.6615 - accuracy: 0.53\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.5312\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.5094\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.5094\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.5312\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5188\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.5406\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.4906\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.5531\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.5188\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5375\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.5375\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.5312\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.5219\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.5219\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.5000\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.5250\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.5156\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.5625\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6601 - accuracy: 0.5281\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6671 - accuracy: 0.5188: 0s - loss: 0.6631 - accuracy: 0.\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.5312\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.5594\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.5437\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.5437\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.4906\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.5125\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.5406\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6660 - accuracy: 0.50 - 0s 5ms/step - loss: 0.6660 - accuracy: 0.5063\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6638 - accuracy: 0.5219\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.5094\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.5344\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.5437\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.4938\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.4969\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.5281\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.5063\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.5250\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.5063\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5250\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5375\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.5375\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.5594\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.5469\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.5188\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.5312\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.5063\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.5281\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.5312\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.5125\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.5156\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.5344\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.5031\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.5312\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.5281\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.5281\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.5375\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.5188\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6645 - accuracy: 0.4969\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6655 - accuracy: 0.5156\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6645 - accuracy: 0.4625\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.5250\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.5000\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.4938\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5312\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.5000\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.5781\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6656 - accuracy: 0.5531\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6668 - accuracy: 0.49 - ETA: 0s - loss: 0.6634 - accuracy: 0.48 - 0s 5ms/step - loss: 0.6632 - accuracy: 0.5031\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.5125\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6619 - accuracy: 0.5125\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6581 - accuracy: 0.51 - 0s 5ms/step - loss: 0.6643 - accuracy: 0.5125\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6633 - accuracy: 0.5219\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6636 - accuracy: 0.4969: 0s - loss: 0.6756 - accuracy: 0.47\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.5281\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6673 - accuracy: 0.4969\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5031\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.5437\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.5500\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.5250\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.4938\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.5375\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5094: 0s - loss: 0.6619 - accuracy: 0.53\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.5188\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.5094\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5219\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.51 - 0s 2ms/step - loss: 0.6640 - accuracy: 0.5156\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.4812\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.5250\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5156\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.4750\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.5500\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.5156\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.5469\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.5281\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.5250\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.5031\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.5031\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6646 - accuracy: 0.4969\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.5281\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.5437\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.5000\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.5219\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.5406\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.5219\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.5094\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.4906\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5281\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.5344\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5094\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5344\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.5188\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.5312\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.5156\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.5063\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.5625: 0s - loss: 0.6653 - accuracy: 0.57\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6665 - accuracy: 0.5000\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5250\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.5094\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6616 - accuracy: 0.5312\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5250\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.5312\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.5094\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.5281\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.5125\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.5031\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5281\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.5063\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.5344\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.4781\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.5219\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5406\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.5094\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.4781\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5250\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.5125\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.5156\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.5063\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.5000\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.4750\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.5219\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5031\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.5031\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.5406\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.5125\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6652 - accuracy: 0.4969: 0s - loss: 0.6497 - accuracy: 0.51\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.5094\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5312\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.5344\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6645 - accuracy: 0.5188\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6565 - accuracy: 0.5437\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.5406\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6593 - accuracy: 0.5219\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6657 - accuracy: 0.4750\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6620 - accuracy: 0.4938\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.5063\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.5000\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.5312\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.5188\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.4875\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.4969\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.5281\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5219\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.4812\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.5625\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.5094\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5156\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.5250\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.4969\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.5437\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.5188\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5281\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.5063\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.5312\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.5219\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.5312\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.5094\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.4844\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.5344\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5219\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.5531\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.5562\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5063\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.5094\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.5063\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.5562\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6653 - accuracy: 0.5063\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.5094\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.5125\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.5312\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5219\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.5219\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.5281\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5063\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.5219\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.5063\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.5219\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.5156\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.5312\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.5219\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.4906\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6627 - accuracy: 0.5188\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.5625\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.5188\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5094\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6627 - accuracy: 0.5219\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5344\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.5375\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.5250\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.5437\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5406\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5281\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.4938\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.4906\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.5219\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.5500\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.5375\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5094\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.5000\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5281\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.5063\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.5188\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.5125\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.5094\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5250\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.4875\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.4938\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5188\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.5281\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6573 - accuracy: 0.5594\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.5281\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6634 - accuracy: 0.5156\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.5312\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.5281\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.5188\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.5375\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.5469\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5312\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6625 - accuracy: 0.4844\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.5312\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.5344\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.5094\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.5094\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.5344\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.5281\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.5219\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.5094\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.5219\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5437\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5188\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.5500\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.4969\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.5063\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.5312\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.5031\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.5250\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.5156\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.5531\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.5031\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.5500\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.5250\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5219\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5375\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.5125\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6631 - accuracy: 0.4938\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.5094\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.5156\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.5156\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.5250\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.5312\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.4938\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.5031\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.5000\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.5000\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.5625\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6624 - accuracy: 0.5219\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.4875\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.5281\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5344\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.5219\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.5188\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5281\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.5375\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.5063\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.5000\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.5125\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.5344\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.5312\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.5312\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.5219\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.5156\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.4812\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.4969\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.5250\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5063\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5344\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.5469\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.5094\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.5500\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.5063\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.5375\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5094\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.5031\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.5437\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.5469\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.5375\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.5125\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.5250\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5125\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.5125\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.5094\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.5125\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.5094\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.5219\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5375\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.5125\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.5500\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.5281\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.5219\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.5063\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.5281\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.5531\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.5469\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.5125\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6615 - accuracy: 0.5156\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.5594\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.5250\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.5500\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.5469\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.5656\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.5188\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.4938\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.5188\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.5375\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6613 - accuracy: 0.5250\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6595 - accuracy: 0.5156\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.5125\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6610 - accuracy: 0.5344\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.5250\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6585 - accuracy: 0.5406\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.5063\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.5125\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.5281\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.5219\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.5250\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6620 - accuracy: 0.5219\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.5344\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6603 - accuracy: 0.5344\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.5094\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.5219\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.5094\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6584 - accuracy: 0.5375\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.5219\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.5094\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.5094\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6608 - accuracy: 0.5281\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.5281\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.5188\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.5156\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.5063\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6603 - accuracy: 0.5063: 0s - loss: 0.6536 - accuracy: 0.\n",
      "Accuracy on training data: 0.5375000238418579% \n",
      " Error on training data: 0.4624999761581421\n",
      "Accuracy on test data: 0.5308641791343689% \n",
      " Error on test data: 0.4691358208656311,\n",
      " Loss: 0.6907597184181213\n"
     ]
    }
   ],
   "source": [
    "mymlp.fit(X_train, y_train, epochs=500, batch_size=10)\n",
    "pred_train= mymlp.predict(X_train)\n",
    "scores = mymlp.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= mymlp.predict(X_test)\n",
    "scores2 = mymlp.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {},\\n Loss: {}'.format(scores2[1], 1 - scores2[1], scores2[0]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a method to hypereparameter tune the model for that problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the tunning also didn't get higher values of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 7)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten())\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  # model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  # model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir\\intro_to_kt\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir\\intro_to_kt\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=100,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=150, validation_split=0.2, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
